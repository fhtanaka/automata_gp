{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "05a151a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "# https://github.com/DEAP/deap/issues/491\n",
    "import numpy as np\n",
    "from deap import algorithms, base, creator, gp, tools\n",
    "from scoop import futures\n",
    "import pygraphviz as pgv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import imageio\n",
    "import pickle\n",
    "import argparse\n",
    "import networkx as nx\n",
    "# import warnings\n",
    "# warnings.simplefilter('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5724f181",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Parameters ################################################\n",
    "TARGET_EMOJI = 0 #@param \"ðŸ¦Ž\"\n",
    "MAX_HEIGHT = 15\n",
    "POPULATION = 400\n",
    "APPLY_SOBEL_FILTER = False\n",
    "VISION = 1\n",
    "TESTS_FOR_EACH_TREE = 1\n",
    "N_TOTAL_STEPS = 100\n",
    "GENS = 30\n",
    "TARGET_IMG = np.full((25,25), .5)\n",
    "SAVETO = None\n",
    "RENDER = False\n",
    "LIMIT = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "73571654",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Test Images ################################################\n",
    "def degrade_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        img[i][:] = 1 - (i*4)/100\n",
    "    return img\n",
    "\n",
    "def column_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        for j in range(25):\n",
    "            if j == 12:\n",
    "                img[i][j] = 1 - (i*4)/100\n",
    "    return img\n",
    "\n",
    "def plus_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        for j in range(25):\n",
    "            if j == 12 or i == 12:\n",
    "                img[i][j] = 0\n",
    "    return img\n",
    "\n",
    "def x_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        for j in range(25):\n",
    "            if j == i or i + j == 24:\n",
    "                img[i][j] = 0\n",
    "    return img\n",
    "\n",
    "def diagonal_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        for j in range(25):\n",
    "            if i + j == 24:\n",
    "                img[i][j] = 0\n",
    "    return img\n",
    "\n",
    "def inv_diagonal_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        for j in range(25):\n",
    "            if i == j:\n",
    "                img[i][j] = 0\n",
    "    return img\n",
    "\n",
    "def fitness(img, target_img):\n",
    "    if img.shape != target_img.shape:\n",
    "        raise\n",
    "    loss = 0\n",
    "    for i in range(target_img.shape[0]):\n",
    "        for j in range(target_img.shape[1]):\n",
    "            if img[i,j] > 1 or img[i,j] < 0 or math.isnan(img[i,j]):\n",
    "                print(i, j, img[i,j])\n",
    "                return -1000\n",
    "            l = img[i,j] - target_img[i,j]\n",
    "            loss += l**2\n",
    "    return 1 - loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "461ef0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Image Convertion functions ################################################\n",
    "def to_rgb(x):\n",
    "    # assume rgb premultiplied by alpha\n",
    "    rgb, a = x[..., :3], to_alpha(x)\n",
    "    return np.clip(1.0-a+rgb, 0, 0.9999)\n",
    "\n",
    "def to_alpha(x):\n",
    "    return np.clip(x[..., 3:4], 0, 0.9999)\n",
    "\n",
    "def to_gray(x):\n",
    "    rgb = to_rgb(x)\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "def print_img(img):\n",
    "    plt.figure(figsize=(4,4))\n",
    "#     plt.imshow(img, cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n",
    "    plt.imshow(to_rgb(img))\n",
    "    plt.show()\n",
    "\n",
    "def load_bw_emoji(index, path=\"data/emoji.png\", size=40):\n",
    "    im = imageio.imread(path)\n",
    "    emoji = np.array(im[:, index*size:(index+1)*size].astype(np.float32))\n",
    "    emoji /= 255.0\n",
    "    gray_emoji = to_gray(emoji)\n",
    "    return gray_emoji\n",
    "\n",
    "def load_emoji(index, path=\"data/emoji.png\", size=40):\n",
    "    im = imageio.imread(path)\n",
    "    emoji = np.array(im[:, index*size:(index+1)*size].astype(np.float32))\n",
    "    emoji /= 255.0\n",
    "    return emoji\n",
    "\n",
    "def plot_loss(loss_log):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title('Loss history (log10)')\n",
    "    plt.plot(np.log10(loss_log), '.', alpha=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "def grayscale_to_rgb(img):\n",
    "    blue_channel = np.array(img*255, dtype = 'uint8')\n",
    "    red_channel = np.array(img*255, dtype = 'uint8')\n",
    "    green_channel = np.array(img*255, dtype = 'uint8')\n",
    "    \n",
    "    return np.stack((red_channel, blue_channel, green_channel), axis=2)\n",
    "\n",
    "def create_base_env(target_image):\n",
    "    env = np.copy(target_image)\n",
    "    env = np.pad(np.copy(target_image), 1)\n",
    "    env[:] = 1\n",
    "    a, b = env.shape\n",
    "    env[int(a/2)][int(b/2)] = 0\n",
    "    return env\n",
    "    \n",
    "def save_graph(expr, name=\"out\"):\n",
    "    nodes, edges, labels = gp.graph(expr)\n",
    "    g = pgv.AGraph()\n",
    "    g.add_nodes_from(nodes)\n",
    "    g.add_edges_from(edges)\n",
    "    g.layout(prog=\"dot\")\n",
    "\n",
    "    for i in nodes:\n",
    "        n = g.get_node(i)\n",
    "        n.attr[\"label\"] = labels[i]\n",
    "    g.draw(name+\".png\")\n",
    "    \n",
    "def draw_graph(expr):\n",
    "    nodes, edges, labels = gp.graph(expr)\n",
    "    g = nx.Graph()\n",
    "    g.add_nodes_from(nodes)\n",
    "    g.add_edges_from(edges)\n",
    "    pos = nx.graphviz_layout(g, prog=\"dot\")\n",
    "\n",
    "    nx.draw_networkx_nodes(g, pos)\n",
    "    nx.draw_networkx_edges(g, pos)\n",
    "    nx.draw_networkx_labels(g, pos, labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "905791f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Automata  ################################################\n",
    "sobel_x = [[-1, 0, +1], [-2, 0, +2], [-1, 0, +1]]\n",
    "sobel_y = np.transpose(sobel_x)\n",
    "class CA_2D_model:\n",
    "    def __init__(self, length, width, layers, individual, *, vision=VISION):\n",
    "        self.action = toolbox.compile(individual)\n",
    "        self.individual = individual\n",
    "        self.len = length + 2*vision\n",
    "        self.wid = width + 2*vision\n",
    "        self.vision = vision\n",
    "        self.vision_size = (vision+2)**2\n",
    "\n",
    "        # The size of the pad is dependent on how far each cell sees to updates its valus\n",
    "        self.original = np.pad(np.zeros((length, width, layers)), vision)\n",
    "        self.original[int(self.len/2)][int(self.wid/2)] = np.ones(layers) # make the center cell black\n",
    "\n",
    "        self.ca = np.copy(self.original)\n",
    "    \n",
    "    def reset_ca(self):\n",
    "        self.ca = np.copy(self.original)\n",
    "\n",
    "    def get_observation(self, i, j):\n",
    "        observation = self.ca[i-self.vision:i+self.vision+1, j-self.vision:j+self.vision+1]\n",
    "        if APPLY_SOBEL_FILTER and self.vision == 1:\n",
    "            sobel_obs = []\n",
    "            for k in range(self.original.shape[2]):\n",
    "                layer = observation[:,:,k]\n",
    "                x = np.multiply(sobel_x, layer) # apply sobel filter for edge detection\n",
    "                y = np.multiply(sobel_y, layer) # apply sobel filter for edge detection\n",
    "                sobel_obs = np.append(sobe_obs, [x.reshape(-1), y.reshape(-1)])\n",
    "            return np.append(observation.reshape(-1), sobel_obs)\n",
    "        return observation.reshape(-1)\n",
    "\n",
    "    def new_cell_value(self, i, j):\n",
    "        # checking if it is a pad\n",
    "        if i-self.vision < 0 or j-self.vision < 0:\n",
    "            return 1\n",
    "        if i+self.vision >= self.len or j + self.vision >= self.wid:\n",
    "            return 1\n",
    "\n",
    "        observation =fa self.get_observation(i, j)\n",
    "        if observation[0:self.vision_size].sum() >= 1 * self.vision_size: # checking if the cell is alive\n",
    "            return 1\n",
    "        value = self.action(*observation)\n",
    "        value = round(value, 5)\n",
    "        value = limit(value, -1*LIMIT, LIMIT)\n",
    "        return value\n",
    "\n",
    "    def update(self):\n",
    "        new_ca = np.copy(self.ca)\n",
    "        for i in range(self.vision, self.len - self.vision): # skipping pad\n",
    "            for j in range(self.vision, self.wid - self.vision): # skipping pad\n",
    "                new_ca[i, j] = self.new_cell_value(i, j)\n",
    "        if (new_ca == self.ca).all(): # checking if the cell updated or not\n",
    "            return False\n",
    "        self.ca = new_ca\n",
    "        return True\n",
    "\n",
    "    def remove_pad(self):\n",
    "        return self.ca[self.vision:self.len - self.vision, self.vision:self.wid - self.vision]\n",
    "\n",
    "    def fitness(self, target_image):\n",
    "        ca = self.remove_pad()\n",
    "        if target_image.shape != ca.shape:\n",
    "            raise\n",
    "        loss = 0\n",
    "        for i in range(target_image.shape[0]):\n",
    "            for j in range(target_image.shape[1]):\n",
    "                if ca[i,j] > 1 or ca[i,j] < 0: # Checking if the cell is in the right interval\n",
    "                    return -1000\n",
    "                l = ca[i,j] - target_image[i,j]\n",
    "                loss += l**2\n",
    "        return 1 - loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "da0ede23",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Creating GP and image ################################################\n",
    "toolbox = base.Toolbox()\n",
    "input_size = (VISION+2)**2\n",
    "if APPLY_SOBEL_FILTER:\n",
    "    input_size *= 3\n",
    "pset = gp.PrimitiveSet(\"MAIN\", input_size) \n",
    "\n",
    "############################################ Node Custom Operations ################################################\n",
    "\n",
    "def protected_div(left, right):\n",
    "    if right == 0:\n",
    "        return 1\n",
    "    return left / right\n",
    "    \n",
    "def limit(input, minimum, maximum):\n",
    "    if input < minimum:\n",
    "        return minimum\n",
    "    elif input > maximum:\n",
    "        return maximum\n",
    "    else:\n",
    "        return input\n",
    "\n",
    "def if_then_else(input, output1, output2):\n",
    "    if input: \n",
    "        return output1\n",
    "    return output2\n",
    "\n",
    "def max(a, b):\n",
    "    if a > b:\n",
    "        return a\n",
    "    return b\n",
    "\n",
    "def min(a, b):\n",
    "    if a < b:\n",
    "        return a\n",
    "    return b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0114d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Creating the GP ################################################\n",
    "# Adding functions\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.sub, 2)\n",
    "pset.addPrimitive(operator.mul, 2)\n",
    "pset.addPrimitive(operator.abs, 1)\n",
    "pset.addPrimitive(protected_div, 2)\n",
    "pset.addPrimitive(limit, 3)\n",
    "pset.addPrimitive(if_then_else, 3)\n",
    "pset.addPrimitive(max, 2)\n",
    "pset.addPrimitive(min, 2)\n",
    "# Adding constants\n",
    "pset.addTerminal(0)\n",
    "pset.addTerminal(1)\n",
    "pset.addTerminal(0.1)\n",
    "pset.addTerminal(0.5)\n",
    "\n",
    "def eval_individual(individual, render=False):\n",
    "    global TARGET_IMG\n",
    "    shape = TARGET_IMG.shape\n",
    "    ca = CA_2D_model(shape[0], shape[1], shape[2], individual)\n",
    "    \n",
    "    total_fitness = 0.0\n",
    "    for i in range(TESTS_FOR_EACH_TREE):\n",
    "        ca.reset_ca()\n",
    "\n",
    "        for _ in range(N_TOTAL_STEPS):\n",
    "            if render:\n",
    "                print_img(ca.remove_pad())\n",
    "                print(ca.fitness(TARGET_IMG))\n",
    "            update = ca.update()\n",
    "            if not update: # the automata got stable\n",
    "                break\n",
    "\n",
    "        total_fitness += ca.fitness(TARGET_IMG)  \n",
    "\n",
    "    fitness = (total_fitness / TESTS_FOR_EACH_TREE) \n",
    "    return (fitness,)\n",
    "\n",
    "creator.create(\"Fitness\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.Fitness)\n",
    "\n",
    "# Tree generator\n",
    "toolbox.register(\"tree_generator\", gp.genHalfAndHalf, pset=pset, min_=1, max_=5)\n",
    "\n",
    "# Structure initializers\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.tree_generator)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"compile\", gp.compile, pset=pset)\n",
    "\n",
    "toolbox.register(\"map\", futures.map)\n",
    "toolbox.register(\"evaluate\", eval_individual)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=7)\n",
    "toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
    "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
    "\n",
    "toolbox.decorate(\"mate\", gp.staticLimit(operator.attrgetter('height'), MAX_HEIGHT))\n",
    "toolbox.decorate(\"mutate\", gp.staticLimit(operator.attrgetter('height'), MAX_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "67f838c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 40, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TARGET_IMG = load_emoji(0, \"data/stick.png\", 25)\n",
    "# TARGET_IMG = load_emoji(0, \"data/brazil.png\", 25)\n",
    "# TARGET_IMG = column_img()\n",
    "# TARGET_IMG = plus_img()\n",
    "# TARGET_IMG = degrade_img()\n",
    "# TARGET_IMG = x_img()\n",
    "# TARGET_IMG = diagonal_img()\n",
    "TARGET_IMG = load_emoji(TARGET_EMOJI)\n",
    "print(TARGET_IMG.shape)\n",
    "for i in range(TARGET_IMG.shape[0]):\n",
    "    for j in range(TARGET_IMG.shape[1]):\n",
    "        for k in range(TARGET_IMG.shape[2]):\n",
    "            TARGET_IMG[i, j, k] = 0\n",
    "print_img(TARGET_IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "24f72d97-7bc9-4b57-b6d1-ffb3813e62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from ipycanvas import Canvas, hold_canvas\n",
    "def scale_matrix(matrix, scale):\n",
    "    return np.kron(matrix, np.ones((scale,scale)))\n",
    "\n",
    "def animate_individual(individual, steps, scale, t):\n",
    "    ca = CA_2D_model(TARGET_IMG.shape[0], TARGET_IMG.shape[1], individual)\n",
    "\n",
    "    canvas = Canvas(width=TARGET_IMG.shape[0]*scale, height=TARGET_IMG.shape[1]*scale)\n",
    "    print(canvas)\n",
    "    display(canvas)\n",
    "\n",
    "    for i in range(steps):\n",
    "        with hold_canvas(canvas):\n",
    "            # Clear the old animation step\n",
    "            canvas.clear()\n",
    "            # Perfom all your drawings here\n",
    "            img = grayscale_to_rgb(scale_matrix(ca.remove_pad(), scale))\n",
    "            _ = canvas.put_image_data(img, 0, 0)\n",
    "\n",
    "            ca.update()\n",
    "\n",
    "        # Animation frequency ~50Hz = 1./50. seconds\n",
    "        sleep(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fb28e407",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<lambda>() takes 9 positional arguments but 36 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6525/2912109562.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m pop, log = algorithms.eaSimple(pop, toolbox, 0.9, 0.3, 10, stats=mstats,\n\u001b[0m\u001b[1;32m     12\u001b[0m                                halloffame=hof, verbose=True)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/deap/algorithms.py\u001b[0m in \u001b[0;36meaSimple\u001b[0;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0minvalid_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6525/3973660382.py\u001b[0m in \u001b[0;36meval_individual\u001b[0;34m(individual, render)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mprint_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTARGET_IMG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# the automata got stable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6525/3304442912.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# skipping pad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwid\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# skipping pad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mnew_ca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_cell_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_ca\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# checking if the cell updated or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6525/3304442912.py\u001b[0m in \u001b[0;36mnew_cell_value\u001b[0;34m(self, i, j)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# checking if the cell is alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mLIMIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLIMIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <lambda>() takes 9 positional arguments but 36 were given"
     ]
    }
   ],
   "source": [
    "pop = toolbox.population(n=POPULATION)\n",
    "hof = tools.HallOfFame(5)\n",
    "\n",
    "stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "mstats = tools.MultiStatistics(fitness=stats_fit)\n",
    "mstats.register(\"avg\", np.mean)\n",
    "mstats.register(\"std\", np.std)\n",
    "mstats.register(\"min\", np.min)\n",
    "mstats.register(\"max\", np.max)\n",
    "\n",
    "pop, log = algorithms.eaSimple(pop, toolbox, 0.9, 0.3, 10, stats=mstats,\n",
    "                               halloffame=hof, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3a10f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "halloffame = None\n",
    "file = \"testes/stick_100g_100s.pkl\"\n",
    "TARGET_IMG = degrade_img()\n",
    "N_TOTAL_STEPS = 25\n",
    "aux = open(file, \"rb\")\n",
    "cp = pickle.load(aux)\n",
    "halloffame = cp[\"halloffame\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a970827-ce09-40ab-b4b7-99ac895740af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas(height=250, width=250)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2d8665fbbc492b9c17d7330f0bfdb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=250, width=250)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "animate_individual(halloffame[2], 100, 10, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92102e09-e551-479f-9804-cc1f8362b6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
