{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05a151a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "# https://github.com/DEAP/deap/issues/491\n",
    "import numpy as np\n",
    "from deap import algorithms, base, creator, gp, tools\n",
    "from scoop import futures\n",
    "import pygraphviz as pgv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import imageio\n",
    "import pickle\n",
    "import argparse\n",
    "import networkx as nx\n",
    "# import warnings\n",
    "# warnings.simplefilter('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5724f181",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Parameters ################################################\n",
    "TARGET_EMOJI = 0 #@param \"ðŸ¦Ž\"\n",
    "MAX_HEIGHT = 15\n",
    "POPULATION = 400\n",
    "APPLY_SOBEL_FILTER = False\n",
    "VISION = 1\n",
    "TESTS_FOR_EACH_TREE = 1\n",
    "N_TOTAL_STEPS = 100\n",
    "GENS = 30\n",
    "TARGET_IMG = np.full((25,25), .5)\n",
    "SAVETO = None\n",
    "RENDER = False\n",
    "LIMIT = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73571654",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Test Images ################################################\n",
    "def degrade_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        img[i][:] = 1 - (i*4)/100\n",
    "    return img\n",
    "\n",
    "def column_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        for j in range(25):\n",
    "            if j == 12:\n",
    "                img[i][j] = 1 - (i*4)/100\n",
    "    return img\n",
    "\n",
    "def plus_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        for j in range(25):\n",
    "            if j == 12 or i == 12:\n",
    "                img[i][j] = 0\n",
    "    return img\n",
    "\n",
    "def x_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        for j in range(25):\n",
    "            if j == i or i + j == 24:\n",
    "                img[i][j] = 0\n",
    "    return img\n",
    "\n",
    "def diagonal_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        for j in range(25):\n",
    "            if i + j == 24:\n",
    "                img[i][j] = 0\n",
    "    return img\n",
    "\n",
    "def inv_diagonal_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        for j in range(25):\n",
    "            if i == j:\n",
    "                img[i][j] = 0\n",
    "    return img\n",
    "\n",
    "def print_img(img):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img, cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n",
    "    plt.show()\n",
    "    \n",
    "def fitness(img, target_img):\n",
    "    if img.shape != target_img.shape:\n",
    "        raise\n",
    "    loss = 0\n",
    "    for i in range(target_img.shape[0]):\n",
    "        for j in range(target_img.shape[1]):\n",
    "            if img[i,j] > 1 or img[i,j] < 0 or math.isnan(img[i,j]):\n",
    "                print(i, j, img[i,j])\n",
    "                return -1000\n",
    "            l = img[i,j] - target_img[i,j]\n",
    "            loss += l**2\n",
    "    return 1 - loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "461ef0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Image Convertion functions ################################################\n",
    "def to_rgb(x):\n",
    "    # assume rgb premultiplied by alpha\n",
    "    rgb, a = x[..., :3], to_alpha(x)\n",
    "    return np.clip(1.0-a+rgb, 0, 0.9999)\n",
    "\n",
    "def to_alpha(x):\n",
    "    return np.clip(x[..., 3:4], 0, 0.9999)\n",
    "\n",
    "def to_gray(x):\n",
    "    rgb = to_rgb(x)\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "\n",
    "def load_emoji(index, path=\"data/emoji.png\", size=40):\n",
    "    im = imageio.imread(path)\n",
    "    emoji = np.array(im[:, index*size:(index+1)*size].astype(np.float32))\n",
    "    emoji /= 255.0\n",
    "    gray_emoji = to_gray(emoji)\n",
    "    return gray_emoji\n",
    "\n",
    "def plot_loss(loss_log):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title('Loss history (log10)')\n",
    "    plt.plot(np.log10(loss_log), '.', alpha=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "def grayscale_to_rgb(img):\n",
    "    blue_channel = np.array(img*255, dtype = 'uint8')\n",
    "    red_channel = np.array(img*255, dtype = 'uint8')\n",
    "    green_channel = np.array(img*255, dtype = 'uint8')\n",
    "    \n",
    "    return np.stack((red_channel, blue_channel, green_channel), axis=2)\n",
    "\n",
    "def create_base_env(target_image):\n",
    "    env = np.copy(target_image)\n",
    "    env = np.pad(np.copy(target_image), 1)\n",
    "    env[:] = 1\n",
    "    a, b = env.shape\n",
    "    env[int(a/2)][int(b/2)] = 0\n",
    "    return env\n",
    "    \n",
    "def save_graph(expr, name=\"out\"):\n",
    "    nodes, edges, labels = gp.graph(expr)\n",
    "    g = pgv.AGraph()\n",
    "    g.add_nodes_from(nodes)\n",
    "    g.add_edges_from(edges)\n",
    "    g.layout(prog=\"dot\")\n",
    "\n",
    "    for i in nodes:\n",
    "        n = g.get_node(i)\n",
    "        n.attr[\"label\"] = labels[i]\n",
    "    g.draw(name+\".png\")\n",
    "    \n",
    "def draw_graph(expr):\n",
    "    nodes, edges, labels = gp.graph(expr)\n",
    "    g = nx.Graph()\n",
    "    g.add_nodes_from(nodes)\n",
    "    g.add_edges_from(edges)\n",
    "    pos = nx.graphviz_layout(g, prog=\"dot\")\n",
    "\n",
    "    nx.draw_networkx_nodes(g, pos)\n",
    "    nx.draw_networkx_edges(g, pos)\n",
    "    nx.draw_networkx_labels(g, pos, labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "905791f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Automata  ################################################\n",
    "sobel_x = [[-1, 0, +1], [-2, 0, +2], [-1, 0, +1]]\n",
    "sobel_y = np.transpose(sobel_x)\n",
    "class CA_2D_model:\n",
    "    def __init__(self, length, width, individual, *, vision=VISION):\n",
    "        self.action = toolbox.compile(individual)\n",
    "        self.individual = individual\n",
    "        self.len = length + 2*vision\n",
    "        self.wid = width + 2*vision\n",
    "        self.vision = vision\n",
    "        self.vision_size = (vision+2)**2\n",
    "\n",
    "        # The size of the pad is dependent on how far each cell sees to updates its valus\n",
    "        self.original = np.pad(np.zeros((length, width)),1)\n",
    "        self.original[:] = 1 # make all cells white\n",
    "        self.original[int(self.len/2)][int(self.wid/2)] = 0 # make the center cell black\n",
    "\n",
    "        self.ca = np.copy(self.original)\n",
    "    \n",
    "    def reset_ca(self):\n",
    "        self.ca = np.copy(self.original)\n",
    "\n",
    "    def get_observation(self, i, j):\n",
    "        observation = self.ca[i-self.vision:i+self.vision+1, j-self.vision:j+self.vision+1]\n",
    "        if APPLY_SOBEL_FILTER and observation.shape == sobel_y.shape:\n",
    "            x = np.multiply(sobel_x, observation) # apply sobel filter for edge detection\n",
    "            y = np.multiply(sobel_y, observation) # apply sobel filter for edge detection\n",
    "            return np.append(observation.reshape(-1), [x.reshape(-1), y.reshape(-1)])\n",
    "        return observation.reshape(-1)\n",
    "\n",
    "    def new_cell_value(self, i, j):\n",
    "        # checking ig it is a pad\n",
    "        if i-self.vision < 0 or j-self.vision < 0:\n",
    "            return 1\n",
    "        if i+self.vision >= self.len or j + self.vision >= self.wid:\n",
    "            return 1\n",
    "\n",
    "        observation = self.get_observation(i, j)\n",
    "        if observation[0:self.vision_size].sum() >= 1 * self.vision_size: # checking if the cell is alive\n",
    "            return 1\n",
    "        value = self.action(*observation)\n",
    "        value = round(value, 5)\n",
    "        value = limit(value, -1*LIMIT, LIMIT)\n",
    "        return value\n",
    "\n",
    "    def update(self):\n",
    "        new_ca = np.copy(self.ca)\n",
    "        for i in range(self.vision, self.len - self.vision): # skipping pad\n",
    "            for j in range(self.vision, self.wid - self.vision): # skipping pad\n",
    "                new_ca[i, j] = self.new_cell_value(i, j)\n",
    "        if (new_ca == self.ca).all(): # checking if the cell updated or not\n",
    "            return False\n",
    "        self.ca = new_ca\n",
    "        return True\n",
    "\n",
    "    def remove_pad(self):\n",
    "        return self.ca[self.vision:self.len - self.vision, self.vision:self.wid - self.vision]\n",
    "\n",
    "    def fitness(self, target_image):\n",
    "        ca = self.remove_pad()\n",
    "        if target_image.shape != ca.shape:\n",
    "            raise\n",
    "        loss = 0\n",
    "        for i in range(target_image.shape[0]):\n",
    "            for j in range(target_image.shape[1]):\n",
    "                if ca[i,j] > 1 or ca[i,j] < 0: # Checking if the cell is in the right interval\n",
    "                    return -1000\n",
    "                l = ca[i,j] - target_image[i,j]\n",
    "                loss += l**2\n",
    "        return 1 - loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da0ede23",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Creating GP and image ################################################\n",
    "toolbox = base.Toolbox()\n",
    "input_size = (VISION+2)**2\n",
    "if APPLY_SOBEL_FILTER:\n",
    "    input_size *= 3\n",
    "pset = gp.PrimitiveSet(\"MAIN\", input_size) \n",
    "\n",
    "############################################ Node Custom Operations ################################################\n",
    "\n",
    "def protected_div(left, right):\n",
    "    if right == 0:\n",
    "        return 1\n",
    "    return left / right\n",
    "    \n",
    "def limit(input, minimum, maximum):\n",
    "    if input < minimum:\n",
    "        return minimum\n",
    "    elif input > maximum:\n",
    "        return maximum\n",
    "    else:\n",
    "        return input\n",
    "\n",
    "def if_then_else(input, output1, output2):\n",
    "    if input: \n",
    "        return output1\n",
    "    return output2\n",
    "\n",
    "def max(a, b):\n",
    "    if a > b:\n",
    "        return a\n",
    "    return b\n",
    "\n",
    "def min(a, b):\n",
    "    if a < b:\n",
    "        return a\n",
    "    return b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0114d888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k1/.local/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Fitness' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/home/k1/.local/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "############################################ Creating the GP ################################################\n",
    "# Adding functions\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.sub, 2)\n",
    "pset.addPrimitive(operator.mul, 2)\n",
    "pset.addPrimitive(operator.abs, 1)\n",
    "pset.addPrimitive(protected_div, 2)\n",
    "pset.addPrimitive(limit, 3)\n",
    "pset.addPrimitive(if_then_else, 3)\n",
    "pset.addPrimitive(max, 2)\n",
    "pset.addPrimitive(min, 2)\n",
    "# Adding constants\n",
    "pset.addTerminal(0)\n",
    "pset.addTerminal(1)\n",
    "pset.addTerminal(0.1)\n",
    "pset.addTerminal(0.5)\n",
    "\n",
    "def eval_individual(individual, render=False):\n",
    "    global TARGET_IMG\n",
    "    shape = TARGET_IMG.shape\n",
    "    ca = CA_2D_model(shape[0], shape[1], individual)\n",
    "    \n",
    "    total_fitness = 0.0\n",
    "    for i in range(TESTS_FOR_EACH_TREE):\n",
    "        ca.reset_ca()\n",
    "\n",
    "        for _ in range(N_TOTAL_STEPS):\n",
    "            if render:\n",
    "                print_img(ca.remove_pad())\n",
    "                print(ca.fitness(TARGET_IMG))\n",
    "            update = ca.update()\n",
    "            if not update: # the automata got stable\n",
    "                break\n",
    "\n",
    "        total_fitness += ca.fitness(TARGET_IMG)  \n",
    "\n",
    "    fitness = (total_fitness / TESTS_FOR_EACH_TREE) \n",
    "    return (fitness,)\n",
    "\n",
    "creator.create(\"Fitness\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.Fitness)\n",
    "\n",
    "# Tree generator\n",
    "toolbox.register(\"tree_generator\", gp.genHalfAndHalf, pset=pset, min_=1, max_=5)\n",
    "\n",
    "# Structure initializers\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.tree_generator)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"compile\", gp.compile, pset=pset)\n",
    "\n",
    "toolbox.register(\"map\", futures.map)\n",
    "toolbox.register(\"evaluate\", eval_individual)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=7)\n",
    "toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
    "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
    "\n",
    "toolbox.decorate(\"mate\", gp.staticLimit(operator.attrgetter('height'), MAX_HEIGHT))\n",
    "toolbox.decorate(\"mutate\", gp.staticLimit(operator.attrgetter('height'), MAX_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67f838c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TARGET_IMG = load_emoji(0, \"data/stick.png\", 25)\n",
    "# TARGET_IMG = load_emoji(0, \"data/brazil.png\", 25)\n",
    "# TARGET_IMG = column_img()\n",
    "# TARGET_IMG = plus_img()\n",
    "# TARGET_IMG = degrade_img()\n",
    "# TARGET_IMG = x_img()\n",
    "# TARGET_IMG = diagonal_img()\n",
    "# TARGET_IMG = load_emoji(command_line_args.img)\n",
    "print_img(TARGET_IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24f72d97-7bc9-4b57-b6d1-ffb3813e62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from ipycanvas import Canvas, hold_canvas\n",
    "def scale_matrix(matrix, scale):\n",
    "    return np.kron(matrix, np.ones((scale,scale)))\n",
    "\n",
    "def animate_individual(individual, steps, scale, t):\n",
    "    ca = CA_2D_model(TARGET_IMG.shape[0], TARGET_IMG.shape[1], individual)\n",
    "\n",
    "    canvas = Canvas(width=TARGET_IMG.shape[0]*scale, height=TARGET_IMG.shape[1]*scale)\n",
    "    print(canvas)\n",
    "    display(canvas)\n",
    "\n",
    "    for i in range(steps):\n",
    "        with hold_canvas(canvas):\n",
    "            # Clear the old animation step\n",
    "            canvas.clear()\n",
    "            # Perfom all your drawings here\n",
    "            img = grayscale_to_rgb(scale_matrix(ca.remove_pad(), scale))\n",
    "            _ = canvas.put_image_data(img, 0, 0)\n",
    "\n",
    "            ca.update()\n",
    "\n",
    "        # Animation frequency ~50Hz = 1./50. seconds\n",
    "        sleep(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb28e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = toolbox.population(n=POPULATION)\n",
    "hof = tools.HallOfFame(5)\n",
    "\n",
    "stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "mstats = tools.MultiStatistics(fitness=stats_fit)\n",
    "mstats.register(\"avg\", np.mean)\n",
    "mstats.register(\"std\", np.std)\n",
    "mstats.register(\"min\", np.min)\n",
    "mstats.register(\"max\", np.max)\n",
    "\n",
    "pop, log = algorithms.eaSimple(pop, toolbox, 0.9, 0.3, 10, stats=mstats,\n",
    "                               halloffame=hof, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3a10f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "halloffame = None\n",
    "file = \"testes/stick_100g_100s.pkl\"\n",
    "TARGET_IMG = degrade_img()\n",
    "N_TOTAL_STEPS = 25\n",
    "aux = open(file, \"rb\")\n",
    "cp = pickle.load(aux)\n",
    "halloffame = cp[\"halloffame\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a970827-ce09-40ab-b4b7-99ac895740af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas(height=250, width=250)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2d8665fbbc492b9c17d7330f0bfdb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=250, width=250)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "animate_individual(halloffame[2], 100, 10, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92102e09-e551-479f-9804-cc1f8362b6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
