{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05a151a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "# https://github.com/DEAP/deap/issues/491\n",
    "import numpy as np\n",
    "import pygraphviz as pgv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import imageio\n",
    "import pickle\n",
    "import argparse\n",
    "import networkx as nx\n",
    "from cgp.graph import Graph\n",
    "from cgp.population import Population\n",
    "# import warnings\n",
    "# warnings.simplefilter('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5724f181",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Parameters ################################################\n",
    "TARGET_EMOJI = 0 #@param \"ðŸ¦Ž\"\n",
    "MAX_HEIGHT = 15\n",
    "POPULATION = 400\n",
    "APPLY_SOBEL_FILTER = False\n",
    "VISION = 1\n",
    "TESTS_FOR_EACH_TREE = 1\n",
    "N_TOTAL_STEPS = 100\n",
    "GENS = 30\n",
    "TARGET_IMG = np.full((25,25), .5)\n",
    "SAVETO = None\n",
    "RENDER = False\n",
    "LIMIT = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73571654",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Test Images ################################################\n",
    "def degrade_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        img[i][:] = 1 - (i*4)/100\n",
    "    return img\n",
    "\n",
    "def column_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        for j in range(25):\n",
    "            if j == 12:\n",
    "                img[i][j] = 1 - (i*4)/100\n",
    "    return img\n",
    "\n",
    "def plus_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        for j in range(25):\n",
    "            if j == 12 or i == 12:\n",
    "                img[i][j] = 0\n",
    "    return img\n",
    "\n",
    "def x_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        for j in range(25):\n",
    "            if j == i or i + j == 24:\n",
    "                img[i][j] = 0\n",
    "    return img\n",
    "\n",
    "def diagonal_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        for j in range(25):\n",
    "            if i + j == 24:\n",
    "                img[i][j] = 0\n",
    "    return img\n",
    "\n",
    "def inv_diagonal_img():\n",
    "    img = np.ones((25,25))\n",
    "    for i in range(25):\n",
    "        for j in range(25):\n",
    "            if i == j:\n",
    "                img[i][j] = 0\n",
    "    return img\n",
    "\n",
    "def print_img(img):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img, cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n",
    "    plt.show()\n",
    "    \n",
    "def fitness(img, target_img):\n",
    "    if img.shape != target_img.shape:\n",
    "        raise\n",
    "    loss = 0\n",
    "    for i in range(target_img.shape[0]):\n",
    "        for j in range(target_img.shape[1]):\n",
    "            if img[i,j] > 1 or img[i,j] < 0 or math.isnan(img[i,j]):\n",
    "                print(i, j, img[i,j])\n",
    "                return -1000\n",
    "            l = img[i,j] - target_img[i,j]\n",
    "            loss += l**2\n",
    "    return 1 - loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "461ef0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Image Convertion functions ################################################\n",
    "def to_rgb(x):\n",
    "    # assume rgb premultiplied by alpha\n",
    "    rgb, a = x[..., :3], to_alpha(x)\n",
    "    return np.clip(1.0-a+rgb, 0, 0.9999)\n",
    "\n",
    "def to_alpha(x):\n",
    "    return np.clip(x[..., 3:4], 0, 0.9999)\n",
    "\n",
    "def to_gray(x):\n",
    "    rgb = to_rgb(x)\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "\n",
    "def load_emoji(index, path=\"data/emoji.png\", size=40):\n",
    "    im = imageio.imread(path)\n",
    "    emoji = np.array(im[:, index*size:(index+1)*size].astype(np.float32))\n",
    "    emoji /= 255.0\n",
    "    gray_emoji = to_gray(emoji)\n",
    "    return gray_emoji\n",
    "\n",
    "def plot_loss(loss_log):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title('Loss history (log10)')\n",
    "    plt.plot(np.log10(loss_log), '.', alpha=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "def grayscale_to_rgb(img):\n",
    "    blue_channel = np.array(img*255, dtype = 'uint8')\n",
    "    red_channel = np.array(img*255, dtype = 'uint8')\n",
    "    green_channel = np.array(img*255, dtype = 'uint8')\n",
    "    \n",
    "    return np.stack((red_channel, blue_channel, green_channel), axis=2)\n",
    "\n",
    "def create_base_env(target_image):\n",
    "    env = np.copy(target_image)\n",
    "    env = np.pad(np.copy(target_image), 1)\n",
    "    env[:] = 1\n",
    "    a, b = env.shape\n",
    "    env[int(a/2)][int(b/2)] = 0\n",
    "    return env\n",
    "    \n",
    "def save_graph(expr, name=\"out\"):\n",
    "    nodes, edges, labels = gp.graph(expr)\n",
    "    g = pgv.AGraph()\n",
    "    g.add_nodes_from(nodes)\n",
    "    g.add_edges_from(edges)\n",
    "    g.layout(prog=\"dot\")\n",
    "\n",
    "    for i in nodes:\n",
    "        n = g.get_node(i)\n",
    "        n.attr[\"label\"] = labels[i]\n",
    "    g.draw(name+\".png\")\n",
    "    \n",
    "def draw_graph(expr):\n",
    "    nodes, edges, labels = gp.graph(expr)\n",
    "    g = nx.Graph()\n",
    "    g.add_nodes_from(nodes)\n",
    "    g.add_edges_from(edges)\n",
    "    pos = nx.graphviz_layout(g, prog=\"dot\")\n",
    "\n",
    "    nx.draw_networkx_nodes(g, pos)\n",
    "    nx.draw_networkx_edges(g, pos)\n",
    "    nx.draw_networkx_labels(g, pos, labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "905791f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Automata  ################################################\n",
    "sobel_x = [[-1, 0, +1], [-2, 0, +2], [-1, 0, +1]]\n",
    "sobel_y = np.transpose(sobel_x)\n",
    "class CA_2D_model:\n",
    "    def __init__(self, length, width, individual, *, vision=VISION):\n",
    "        self.action = toolbox.compile(individual)\n",
    "        self.individual = individual\n",
    "        self.len = length + 2*vision\n",
    "        self.wid = width + 2*vision\n",
    "        self.vision = vision\n",
    "        self.vision_size = (vision+2)**2\n",
    "\n",
    "        # The size of the pad is dependent on how far each cell sees to updates its valus\n",
    "        self.original = np.pad(np.zeros((length, width)),1)\n",
    "        self.original[:] = 1 # make all cells white\n",
    "        self.original[int(self.len/2)][int(self.wid/2)] = 0 # make the center cell black\n",
    "\n",
    "        self.ca = np.copy(self.original)\n",
    "    \n",
    "    def reset_ca(self):\n",
    "        self.ca = np.copy(self.original)\n",
    "\n",
    "    def get_observation(self, i, j):\n",
    "        observation = self.ca[i-self.vision:i+self.vision+1, j-self.vision:j+self.vision+1]\n",
    "        if APPLY_SOBEL_FILTER and observation.shape == sobel_y.shape:\n",
    "            x = np.multiply(sobel_x, observation) # apply sobel filter for edge detection\n",
    "            y = np.multiply(sobel_y, observation) # apply sobel filter for edge detection\n",
    "            return np.append(observation.reshape(-1), [x.reshape(-1), y.reshape(-1)])\n",
    "        return observation.reshape(-1)\n",
    "\n",
    "    def new_cell_value(self, i, j):\n",
    "        # checking ig it is a pad\n",
    "        if i-self.vision < 0 or j-self.vision < 0:\n",
    "            return 1\n",
    "        if i+self.vision >= self.len or j + self.vision >= self.wid:\n",
    "            return 1\n",
    "\n",
    "        observation = self.get_observation(i, j)\n",
    "        if observation[0:self.vision_size].sum() >= 1 * self.vision_size: # checking if the cell is alive\n",
    "            return 1\n",
    "        value = self.action(*observation)\n",
    "        value = round(value, 5)\n",
    "        value = limit(value, -1*LIMIT, LIMIT)\n",
    "        return value\n",
    "\n",
    "    def update(self):\n",
    "        new_ca = np.copy(self.ca)\n",
    "        for i in range(self.vision, self.len - self.vision): # skipping pad\n",
    "            for j in range(self.vision, self.wid - self.vision): # skipping pad\n",
    "                new_ca[i, j] = self.new_cell_value(i, j)\n",
    "        if (new_ca == self.ca).all(): # checking if the cell updated or not\n",
    "            return False\n",
    "        self.ca = new_ca\n",
    "        return True\n",
    "\n",
    "    def remove_pad(self):\n",
    "        return self.ca[self.vision:self.len - self.vision, self.vision:self.wid - self.vision]\n",
    "\n",
    "    def fitness(self, target_image):\n",
    "        ca = self.remove_pad()\n",
    "        if target_image.shape != ca.shape:\n",
    "            raise\n",
    "        loss = 0\n",
    "        for i in range(target_image.shape[0]):\n",
    "            for j in range(target_image.shape[1]):\n",
    "                if ca[i,j] > 1 or ca[i,j] < 0: # Checking if the cell is in the right interval\n",
    "                    return -1000\n",
    "                l = ca[i,j] - target_image[i,j]\n",
    "                loss += l**2\n",
    "        return 1 - loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da0ede23",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Creating GP and image ################################################\n",
    "input_size = (VISION+2)**2\n",
    "if APPLY_SOBEL_FILTER:\n",
    "    input_size *= 3\n",
    "\n",
    "############################################ Node Custom Operations ################################################\n",
    "\n",
    "addition = lambda x, y: x+y\n",
    "multiplication = lambda x, y: x*y\n",
    "subtraction = lambda x, y: x-y\n",
    "constant = lambda x: x\n",
    "protected_div = lambda x, y: 1 if y == 0 else x/y\n",
    "increment = lambda x: x+1\n",
    "invert = lambda x: -x\n",
    "\n",
    "seed = 2002\n",
    "Graph.rng = np.random.RandomState(seed)\n",
    "\n",
    "Population.add_operation(arity=1, func=constant, string=\"x\")\n",
    "Population.add_operation(arity=1, func=increment, string=\"x+1\")\n",
    "Population.add_operation(arity=1, func=invert, string=\"-x\")\n",
    "Population.add_operation(arity=2, func=addition, string=\"x+y\")\n",
    "Population.add_operation(arity=2, func=multiplication, string=\"x*y\")\n",
    "Population.add_operation(arity=2, func=subtraction, string=\"x-y\")\n",
    "Population.add_operation(arity=2, func=protected_div, string=\"*x/y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0114d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_individual(individual, render=False):\n",
    "    global TARGET_IMG\n",
    "    shape = TARGET_IMG.shape\n",
    "    ca = CA_2D_model(shape[0], shape[1], individual)\n",
    "    \n",
    "    total_fitness = 0.0\n",
    "    for i in range(TESTS_FOR_EACH_TREE):\n",
    "        ca.reset_ca()\n",
    "\n",
    "        for _ in range(N_TOTAL_STEPS):\n",
    "            if render:\n",
    "                print_img(ca.remove_pad())\n",
    "                print(ca.fitness(TARGET_IMG))\n",
    "            update = ca.update()\n",
    "            if not update: # the automata got stable\n",
    "                break\n",
    "\n",
    "        total_fitness += ca.fitness(TARGET_IMG)  \n",
    "\n",
    "    fitness = (total_fitness / TESTS_FOR_EACH_TREE) \n",
    "    return (fitness,)\n",
    "\n",
    "def fitness_func(individual: Graph, tests):\n",
    "\n",
    "    fitness = 0\n",
    "    for t in tests:\n",
    "        pred1, pred2 = individual.operate([t[0][0], t[0][1]])\n",
    "        fitness += (t[1][0] - pred1)**2 + (t[1][1] - pred2)**2\n",
    "\n",
    "        # pred1 = individual.operate(t[0])[0]\n",
    "        # fitness += (t[1][0] - pred1)**2\n",
    "    return  fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67f838c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TARGET_IMG = load_emoji(0, \"data/stick.png\", 25)\n",
    "# TARGET_IMG = load_emoji(0, \"data/brazil.png\", 25)\n",
    "# TARGET_IMG = column_img()\n",
    "# TARGET_IMG = plus_img()\n",
    "TARGET_IMG = degrade_img()\n",
    "# TARGET_IMG = x_img()\n",
    "# TARGET_IMG = diagonal_img()\n",
    "# TARGET_IMG = load_emoji(command_line_args.img)\n",
    "print_img(TARGET_IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24f72d97-7bc9-4b57-b6d1-ffb3813e62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from ipycanvas import Canvas, hold_canvas\n",
    "def scale_matrix(matrix, scale):\n",
    "    return np.kron(matrix, np.ones((scale,scale)))\n",
    "\n",
    "def animate_individual(individual, steps, scale, t):\n",
    "    ca = CA_2D_model(TARGET_IMG.shape[0], TARGET_IMG.shape[1], individual)\n",
    "\n",
    "    canvas = Canvas(width=TARGET_IMG.shape[0]*scale, height=TARGET_IMG.shape[1]*scale)\n",
    "    print(canvas)\n",
    "    display(canvas)\n",
    "\n",
    "    for i in range(steps):\n",
    "        with hold_canvas(canvas):\n",
    "            # Clear the old animation step\n",
    "            canvas.clear()\n",
    "            # Perfom all your drawings here\n",
    "            img = grayscale_to_rgb(scale_matrix(ca.remove_pad(), scale))\n",
    "            _ = canvas.put_image_data(img, 0, 0)\n",
    "\n",
    "            ca.update()\n",
    "\n",
    "        # Animation frequency ~50Hz = 1./50. seconds\n",
    "        sleep(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb28e407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \t      \t                        fitness                        \n",
      "   \t      \t-------------------------------------------------------\n",
      "gen\tnevals\tavg     \tgen\tmax   \tmin  \tnevals\tstd    \n",
      "0  \t400   \t-314.498\t0  \t-51.25\t-1000\t400   \t291.939\n",
      "1  \t379   \t-196.492\t1  \t-51.25\t-1000\t379   \t154.105\n",
      "2  \t374   \t-184.015\t2  \t-46.7 \t-1000\t374   \t214.659\n"
     ]
    }
   ],
   "source": [
    "pop = toolbox.population(n=POPULATION)\n",
    "hof = tools.HallOfFame(5)\n",
    "\n",
    "stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "mstats = tools.MultiStatistics(fitness=stats_fit)\n",
    "mstats.register(\"avg\", np.mean)\n",
    "mstats.register(\"std\", np.std)\n",
    "mstats.register(\"min\", np.min)\n",
    "mstats.register(\"max\", np.max)\n",
    "\n",
    "pop, log = algorithms.eaSimple(pop, toolbox, 0.9, 0.3, 10, stats=mstats,\n",
    "                               halloffame=hof, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "halloffame = None\n",
    "file = \"testes/stick_100g_100s.pkl\"\n",
    "TARGET_IMG = degrade_img()\n",
    "N_TOTAL_STEPS = 25\n",
    "aux = open(file, \"rb\")\n",
    "cp = pickle.load(aux)\n",
    "halloffame = cp[\"halloffame\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a970827-ce09-40ab-b4b7-99ac895740af",
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_individual(halloffame[2], 100, 10, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92102e09-e551-479f-9804-cc1f8362b6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
