{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92102e09-e551-479f-9804-cc1f8362b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cgp.graph import Graph\n",
    "from cgp.population import Population\n",
    "from automata import CA_2D_model\n",
    "import test_images\n",
    "from arg_parser import parse_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e2d7980-07d5-4466-8441-16c65854d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_EMOJI = 0  # @param \"ðŸ¦Ž\"\n",
    "MAX_HEIGHT = 15\n",
    "POPULATION = 4\n",
    "APPLY_SOBEL_FILTER = False\n",
    "VISION = 1\n",
    "TESTS_FOR_EACH_TREE = 1\n",
    "N_TOTAL_STEPS = 100\n",
    "GENS = 30\n",
    "SAVETO = None\n",
    "RENDER = False\n",
    "LIMIT = 10000\n",
    "EXTRA_LAYERS = 3\n",
    "GEN_CHAMPIONS = 1\n",
    "FITNESS_GOAL = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b149b459-e848-48cb-a90f-f33022ca403f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TARGET_IMG = test_images.load_emoji(0, \"data/stick.png\", 25)\n",
    "# TARGET_IMG = test_images.load_emoji(0, \"data/brazil.png\", 25)\n",
    "# TARGET_IMG = test_images.column_img()\n",
    "# TARGET_IMG = test_images.plus_img()\n",
    "TARGET_IMG = test_images.degrade_img()\n",
    "# TARGET_IMG = test_images.x_img()\n",
    "# TARGET_IMG = test_images.diagonal_img()\n",
    "# TARGET_IMG = test_images.load_emoji(command_line_args.img)\n",
    "test_images.print_img(TARGET_IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5222254-b043-41ad-ab67-4cb152995fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (VISION+2)**2\n",
    "if APPLY_SOBEL_FILTER:\n",
    "    input_size *= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18fe4255-d80a-44ce-878d-92d8f3b97e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "addition = lambda x, y: x+y\n",
    "multiplication = lambda x, y: x*y\n",
    "subtraction = lambda x, y: x-y\n",
    "constant = lambda x: x\n",
    "protected_div = lambda x, y: 1 if y == 0 else x/y\n",
    "increment = lambda x: x+1\n",
    "invert = lambda x: -x\n",
    "\n",
    "seed = 2002\n",
    "Graph.rng = np.random.RandomState(seed)\n",
    "\n",
    "Population.add_operation(arity=1, func=lambda x: 1, string=\"1\")\n",
    "Population.add_operation(arity=1, func=lambda x: .5, string=\"0.5\")\n",
    "Population.add_operation(arity=1, func=lambda x: .1, string=\"0.1\")\n",
    "Population.add_operation(arity=1, func=constant, string=\"x\")\n",
    "Population.add_operation(arity=1, func=increment, string=\"x+1\")\n",
    "Population.add_operation(arity=1, func=invert, string=\"-x\")\n",
    "Population.add_operation(arity=2, func=addition, string=\"x+y\")\n",
    "Population.add_operation(arity=2, func=multiplication, string=\"x*y\")\n",
    "Population.add_operation(arity=2, func=subtraction, string=\"x-y\")\n",
    "Population.add_operation(arity=2, func=protected_div, string=\"*x/y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c286e8fc-29ec-4e28-9d92-a5eeab995972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_individual(individual: Graph, target_image, layers, render=False):\n",
    "    shape = target_image.shape\n",
    "    ca = CA_2D_model(shape[0], shape[1], individual.operate, layers)\n",
    "    \n",
    "    total_fitness = 0.0\n",
    "    for i in range(TESTS_FOR_EACH_TREE):\n",
    "        ca.reset_ca()\n",
    "\n",
    "        for _ in range(N_TOTAL_STEPS):\n",
    "            if render:\n",
    "                test_images.print_img(ca.remove_pad())\n",
    "                print(ca.fitness(target_image))\n",
    "            update = ca.update()\n",
    "            if not update: # the automata got stable\n",
    "                break\n",
    "\n",
    "        total_fitness += ca.fitness(target_image)  \n",
    "\n",
    "    fitness = (total_fitness / TESTS_FOR_EACH_TREE) \n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbbbbeee-98e7-4795-b51b-79d229fda96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_IMG = test_images.degrade_img()\n",
    "# test_images.print_img(TARGET_IMG)\n",
    "total_layers = 1 + EXTRA_LAYERS\n",
    "population = Population(\n",
    "    population_size=POPULATION,\n",
    "    n_in=total_layers*input_size,\n",
    "    n_out=total_layers,\n",
    "    n_row=8,\n",
    "    n_col=4,\n",
    "    levels_back=5,\n",
    "    mutation_strategy=\"prob\",\n",
    "    fitness_func=lambda x: eval_individual(x, TARGET_IMG, total_layers),\n",
    "    minimize_fitness=True,\n",
    "    point_mut_qnt=10,\n",
    "    prob_mut_chance=.2,\n",
    "    mutate_active_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f204786-6fb1-44ce-addc-c1e437548c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  0\n",
      "0  fit:  52.24999999999994\n",
      "1  fit:  162.2499999999999\n",
      "2  fit:  196.00000000000054\n",
      "3  fit:  196.00000000000054\n",
      "Best fitness of gen:  52.24999999999994\n",
      "generation  1\n",
      "0  fit:  52.24999999999994\n",
      "4  fit:  196.00000000000054\n",
      "5  fit:  52.24999999999994\n",
      "6  fit:  52.24999999999994\n",
      "7  fit:  52.24999999999994\n",
      "Best fitness of gen:  52.24999999999994\n",
      "generation  2\n",
      "7  fit:  52.24999999999994\n",
      "8  fit:  196.00000000000054\n",
      "9  fit:  52.24999999999994\n",
      "10  fit:  196.25000000000054\n",
      "11  fit:  1000.0\n",
      "Best fitness of gen:  52.24999999999994\n",
      "generation  3\n",
      "9  fit:  52.24999999999994\n",
      "12  fit:  196.00000000000054\n",
      "13  fit:  196.00000000000054\n",
      "14  fit:  162.2499999999999\n",
      "15  fit:  52.24999999999994\n",
      "Best fitness of gen:  52.24999999999994\n",
      "generation  4\n",
      "15  fit:  52.24999999999994\n",
      "16  fit:  52.24999999999994\n",
      "17  fit:  52.24999999999994\n",
      "18  fit:  52.24999999999994\n",
      "19  fit:  196.00000000000054\n",
      "Best fitness of gen:  52.24999999999994\n",
      "generation  5\n",
      "18  fit:  52.24999999999994\n",
      "20  fit:  162.2499999999999\n",
      "21  fit:  52.24999999999994\n",
      "22  fit:  196.00000000000054\n",
      "23  fit:  52.24999999999994\n",
      "Best fitness of gen:  52.24999999999994\n",
      "generation  6\n",
      "23  fit:  52.24999999999994\n",
      "24  fit:  52.24999999999994\n",
      "25  fit:  52.24999999999994\n",
      "26  fit:  52.24999999999994\n",
      "27  fit:  52.24999999999994\n",
      "Best fitness of gen:  52.24999999999994\n",
      "generation  7\n",
      "27  fit:  52.24999999999994\n",
      "28  fit:  196.00000000000054\n",
      "29  fit:  52.24999999999994\n",
      "30  fit:  52.24999999999994\n",
      "31  fit:  52.24999999999994\n",
      "Best fitness of gen:  52.24999999999994\n",
      "generation  8\n",
      "31  fit:  52.24999999999994\n",
      "32  fit:  52.24999999999994\n",
      "33  fit:  52.24999999999994\n",
      "34  fit:  52.24999999999994\n",
      "35  fit:  52.24999999999994\n",
      "Best fitness of gen:  52.24999999999994\n",
      "generation  9\n",
      "35  fit:  52.24999999999994\n",
      "36  fit:  56.000000000000036\n",
      "37  fit:  52.24999999999994\n",
      "38  fit:  52.24999999999994\n",
      "39  fit:  52.24999999999994\n",
      "Best fitness of gen:  52.24999999999994\n",
      "Finished execution\n",
      "Total generations: 9\n",
      "Best Fitness: 52.24999999999994\n"
     ]
    }
   ],
   "source": [
    "population.one_plus_lamda(10, GEN_CHAMPIONS, FITNESS_GOAL, report = True)\n",
    "# return pop, log, hof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fcd899d-3524-49e2-94e4-12c4a74afed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from ipycanvas import Canvas, hold_canvas\n",
    "def scale_matrix(matrix, scale):\n",
    "    return np.kron(matrix, np.ones((scale,scale)))\n",
    "\n",
    "def animate_individual(individual, steps, scale, t):\n",
    "    shape = TARGET_IMG.shape\n",
    "    ca = CA_2D_model(shape[0], shape[1], individual.operate, 1 + EXTRA_LAYERS)\n",
    "\n",
    "    canvas = Canvas(width=TARGET_IMG.shape[0]*scale, height=TARGET_IMG.shape[1]*scale)\n",
    "    print(canvas)\n",
    "    display(canvas)\n",
    "\n",
    "    for i in range(steps):\n",
    "        with hold_canvas(canvas):\n",
    "            # Clear the old animation step\n",
    "            canvas.clear()\n",
    "            # Perfom all your drawings here\n",
    "            img = test_images.grayscale_to_rgb(scale_matrix(ca.remove_pad(), scale))\n",
    "            _ = canvas.put_image_data(img, 0, 0)\n",
    "\n",
    "            update = ca.update()\n",
    "            if not update: # the automata got stable\n",
    "                break\n",
    "\n",
    "        # Animation frequency ~50Hz = 1./50. seconds\n",
    "        sleep(t)\n",
    "    print(\"AA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43857563-65ea-4621-86be-097a84d7f6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas(height=250, width=250)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb9e5f33a0d47758505de97924da732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=250, width=250)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hof =population.get_best_indvs(1)\n",
    "animate_individual(hof[0], 100, 10, 0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a7c8d-e388-4fd1-918b-27137a40861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ind in population.indvs:\n",
    "    eval_individual(ind, TARGET_IMG, total_layers, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
